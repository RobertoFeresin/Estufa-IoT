#!/bin/bash
set -e

echo "üßπ Limpando containers antigos..."
podman rm -af || true

echo "üßπ Limpando imagens antigas..."
podman rmi -af || true

echo "üî™ Matando qualquer processo ocupando a porta 11434..."
if sudo lsof -t -i:11434 >/dev/null 2>&1; then
  sudo fuser -k 11434/tcp || true
  echo "‚úÖ Porta 11434 liberada!"
else
  echo "‚ÑπÔ∏è Nenhum processo usando a porta 11434."
fi


echo "üî® Rebuildando backend..."
podman build -t estufa-backend .

echo "üåê Garantindo rede estufa-net..."
if ! podman network exists estufa-net; then
  podman network create estufa-net
fi

echo "üì¶ Subindo InfluxDB..."
mkdir -p ./data ./data/exports
podman run -d --name influxdb --network estufa-net \
  -p 8086:8086 \
  -v ./data:/var/lib/influxdb:Z \
  docker.io/library/influxdb:1.8

echo "üì¶ Subindo Backend (Flask)..."
podman run -d --name backend --network estufa-net \
  -e SIMULATE=1 \
  -e INFLUX_HOST=influxdb \
  -e INFLUX_DB=estufa \
  -e EXPORT_PATH=/app/exports/sensores.csv \
  -p 5000:5000 \
  -v ./data/exports:/app/exports:Z \
  localhost/estufa-backend:latest

echo "üì¶ Subindo Frontend (Nginx)..."
if [ ! -d "./frontend/dist" ]; then
  echo "‚ö†Ô∏è  Pasta ./frontend/dist n√£o encontrada! Rode 'npm run build' em ./frontend antes."
else
  podman run -d --name frontend --network estufa-net \
    -p 8081:80 \
    -v ./frontend/dist:/usr/share/nginx/html:Z \
    docker.io/library/nginx:alpine
fi

echo "ü§ñ Subindo Ollama (IA local)..."

if podman ps -a --format '{{.Names}}' | grep -q '^ollama$'; then
  podman stop ollama >/dev/null 2>&1 || true
  podman rm ollama >/dev/null 2>&1 || true
fi
if podman volume exists ollama; then
  echo "üß® Removendo volume antigo do Ollama..."
  podman volume rm ollama >/dev/null 2>&1 || true
fi

podman pull docker.io/ollama/ollama:latest

podman run -d \
  --name ollama \
  --network estufa-net \
  -p 11434:11434 \
  -e HOME=/root \
  -v ollama:/root/.ollama \
  docker.io/ollama/ollama:latest

echo "‚è≥ Aguardando Ollama iniciar..."
sleep 6

if curl -s http://localhost:11434 | grep -q "Ollama is running"; then
  echo "‚úÖ Ollama est√° rodando corretamente."
else
  echo "‚ùå Falha ao iniciar Ollama. Verifique o Podman."
  exit 1
fi

echo "üì¶ Baixando modelo leve 'qwen2:1.5b'..."
podman exec -it ollama ollama pull qwen2:1.5b || {
  echo "‚ö†Ô∏è Falha ao puxar modelo automaticamente. Tente manualmente depois com:"
  echo "   podman exec -it ollama ollama pull qwen2:1.5b"
}

echo "üìã Modelos dispon√≠veis:"
podman exec -it ollama ollama list || true

echo ""
echo "‚úÖ Todos os servi√ßos foram iniciados com sucesso!"
echo "‚û°Ô∏è  Backend:   http://localhost:5000/dados"
echo "‚û°Ô∏è  Frontend:  http://localhost:8081"
echo "‚û°Ô∏è  InfluxDB:  http://localhost:8086/ping"
echo "‚û°Ô∏è  IA (Ollama): http://localhost:11434"
echo ""
echo "üéØ Modelo 'qwen2:1.5b' instalado e pronto pra responder no chat!"
